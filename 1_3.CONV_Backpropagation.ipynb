{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv_op:\n",
    "  # A Convolution layer using 3x3 filters.\n",
    "\n",
    "  def __init__(self, num_filters):\n",
    "    self.num_filters = num_filters\n",
    "\n",
    "    self.filters = np.random.randn(num_filters, 3, 3) / 9\n",
    "\n",
    "  def iterate_regions(self, image):\n",
    "    \n",
    "    h, w = image.shape\n",
    "\n",
    "    for i in range(h - 2):\n",
    "      for j in range(w - 2):\n",
    "        im_region = image[i:(i + 3), j:(j + 3)]\n",
    "        yield im_region, i, j\n",
    "\n",
    "  def forward(self, input):\n",
    "    \n",
    "    self.last_input = input\n",
    "\n",
    "    h, w = input.shape\n",
    "    output = np.zeros((h - 2, w - 2, self.num_filters))\n",
    "\n",
    "    for im_region, i, j in self.iterate_regions(input):\n",
    "      output[i, j] = np.sum(im_region * self.filters, axis=(1, 2))\n",
    "\n",
    "    return output\n",
    "\n",
    "  def backprop(self, d_L_d_out, learn_rate):\n",
    "    \n",
    "    d_L_d_filters = np.zeros(self.filters.shape)\n",
    "\n",
    "    for im_region, i, j in self.iterate_regions(self.last_input):\n",
    "      for f in range(self.num_filters):\n",
    "        d_L_d_filters[f] += d_L_d_out[i, j, f] * im_region\n",
    "\n",
    "    \n",
    "    self.filters -= learn_rate * d_L_d_filters\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Max_pool:\n",
    "  # A Max Pooling layer using a pool size of 2.\n",
    "\n",
    "  def iterate_regions(self, image):\n",
    "    \n",
    "    h, w, _ = image.shape\n",
    "    new_h = h // 2\n",
    "    new_w = w // 2\n",
    "\n",
    "    for i in range(new_h):\n",
    "      for j in range(new_w):\n",
    "        im_region = image[(i * 2):(i * 2 + 2), (j * 2):(j * 2 + 2)]\n",
    "        yield im_region, i, j\n",
    "\n",
    "  def forward(self, input):\n",
    "   \n",
    "    self.last_input = input\n",
    "\n",
    "    h, w, num_filters = input.shape\n",
    "    output = np.zeros((h // 2, w // 2, num_filters))\n",
    "\n",
    "    for im_region, i, j in self.iterate_regions(input):\n",
    "      output[i, j] = np.amax(im_region, axis=(0, 1))\n",
    "\n",
    "    return output\n",
    "\n",
    "  def backprop(self, d_L_d_out):\n",
    "    \n",
    "    d_L_d_input = np.zeros(self.last_input.shape)\n",
    "\n",
    "    for im_region, i, j in self.iterate_regions(self.last_input):\n",
    "      h, w, f = im_region.shape\n",
    "      amax = np.amax(im_region, axis=(0, 1))\n",
    "\n",
    "      for i2 in range(h):\n",
    "        for j2 in range(w):\n",
    "          for f2 in range(f):\n",
    "            # If this pixel was the max value, copy the gradient to it.\n",
    "            if im_region[i2, j2, f2] == amax[f2]:\n",
    "              d_L_d_input[i * 2 + i2, j * 2 + j2, f2] = d_L_d_out[i, j, f2]\n",
    "\n",
    "    return d_L_d_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "\n",
    "    def __init__(self, input_len, nodes):\n",
    "        self.weights = np.random.randn(input_len, nodes) / input_len\n",
    "        self.biases = np.zeros(nodes)\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.last_input_shape = input.shape\n",
    "        \n",
    "        input = input.flatten()\n",
    "        self.last_input = input\n",
    "\n",
    "        input_len, nodes = self.weights.shape\n",
    "\n",
    "        totals = np.dot(input, self.weights) + self.biases\n",
    "        self.last_totals = totals\n",
    " \n",
    "        exp = np.exp(totals)\n",
    "        return exp / np.sum(exp, axis=0)\n",
    "    \n",
    "    def backprop(self, d_L_d_out, learn_rate):\n",
    "    # We know only 1 element of d_L_d_out will be nonzero\n",
    "         for i, gradient in enumerate(d_L_d_out):\n",
    "            if gradient == 0:\n",
    "                continue\n",
    "            t_exp = np.exp(self.last_totals)\n",
    "\n",
    "      # Sum of all e^totals\n",
    "            S = np.sum(t_exp)\n",
    "\n",
    "      # Gradients of out[i] against totals\n",
    "            d_out_d_t = -t_exp[i] * t_exp / (S ** 2)\n",
    "            d_out_d_t[i] = t_exp[i] * (S - t_exp[i]) / (S ** 2)\n",
    "\n",
    "      # Gradients of totals against weights/biases/input\n",
    "            d_t_d_w = self.last_input\n",
    "            d_t_d_b = 1\n",
    "            d_t_d_inputs = self.weights\n",
    "\n",
    "      # Gradients of loss against totals\n",
    "            d_L_d_t = gradient * d_out_d_t\n",
    "\n",
    "      # Gradients of loss against weights/biases/input\n",
    "            d_L_d_w = d_t_d_w[np.newaxis].T @ d_L_d_t[np.newaxis]\n",
    "            d_L_d_b = d_L_d_t * d_t_d_b\n",
    "            d_L_d_inputs = d_t_d_inputs @ d_L_d_t\n",
    "\n",
    "      # Update weights / biases\n",
    "            self.weights -= learn_rate * d_L_d_w\n",
    "            self.biases -= learn_rate * d_L_d_b\n",
    "\n",
    "            return d_L_d_inputs.reshape(self.last_input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 250, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path=r'C:\\Users\\STACBD\\bangla-money\\Training\\1\\1_0.jpg'\n",
    "a = plt.imread(image_path)\n",
    "a = np.array(a)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[..., :3], [0.299, 0.587, 0.144])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 250)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = rgb2gray(a)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118, 248, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = Conv_op(8)\n",
    "out = conn.forward(X)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59, 124, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool = Max_pool()  \n",
    "out2 = pool.forward(out)\n",
    "out2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10181045 0.09681898 0.08962254 0.12933633 0.11885105 0.09979783\n",
      " 0.15502615 0.11782091 0.09091576]\n"
     ]
    }
   ],
   "source": [
    "soft=Softmax(59* 124* 8, 9)\n",
    "out3=soft.forward(out2)\n",
    "print(out3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = []\n",
    "\n",
    "\n",
    "def img_read(number, loop):\n",
    "    for i in range(loop):\n",
    "        a = plt.imread(\n",
    "            \"C:\\\\Users\\\\STACBD\\\\bangla-money\\\\Training\\\\\"\n",
    "            + str(number)\n",
    "            + \"\\\\\"\n",
    "            + str(number)\n",
    "            + \"_\"\n",
    "            + str(i)\n",
    "            + \".jpg\"\n",
    "        )\n",
    "        a = np.array(a)\n",
    "        folder.append(a)\n",
    "    ax = np.array(folder)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "\n",
    "\n",
    "def label(number, loop):\n",
    "    for i in range(loop):\n",
    "        if number == 1:\n",
    "            y.append(0)\n",
    "        elif number == 2:\n",
    "            y.append(1)\n",
    "        elif number == 5:\n",
    "            y.append(2)\n",
    "        elif number == 10:\n",
    "            y.append(3)\n",
    "        elif number == 20:\n",
    "            y.append(4)\n",
    "        elif number == 50:\n",
    "            y.append(5)\n",
    "        elif number == 100:\n",
    "            y.append(6)\n",
    "        elif number == 500:\n",
    "            y.append(7)\n",
    "        elif number == 1000:\n",
    "            y.append(8)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_taka = img_read(1, 100)\n",
    "one = label(1, 100)\n",
    "two_taka = img_read(2, 212)\n",
    "two = label(2, 212)\n",
    "five_taka = img_read(5, 212)\n",
    "five = label(5, 212)\n",
    "ten_taka = img_read(10, 212)\n",
    "ten = label(10, 212)\n",
    "fifty_taka = img_read(50, 212)\n",
    "fifty = label(50, 212)\n",
    "hundred_taka = img_read(100, 203)\n",
    "hundred = label(100, 203)\n",
    "five_hundred_taka = img_read(500, 135)\n",
    "five_hundred = label(500, 135)\n",
    "one_thousand_taka = img_read(1000, 166)\n",
    "one_thousand = label(1000, 166)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 8 8 8]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1452,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(y)\n",
    "print(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = np.array(folder)\n",
    "folder.shape\n",
    "X = np.array(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[..., :3], [0.299, 0.587, 0.144])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = rgb2gray(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=42, test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(image, label):\n",
    "  out = conn.forward((image / 255) - 0.5)\n",
    "  out = pool.forward(out)\n",
    "  out = soft.forward(out)\n",
    "  loss = -np.log(out[label])\n",
    "  acc = 1 if np.argmax(out) == label else 0\n",
    "    \n",
    "  return out, loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ForwardPass\n",
      "[Step 100] : Loss 2.20 && Accuracy: 16%\n",
      "[Step 200] : Loss 2.20 && Accuracy: 8%\n",
      "[Step 300] : Loss 2.20 && Accuracy: 13%\n",
      "[Step 400] : Loss 2.20 && Accuracy: 14%\n",
      "[Step 500] : Loss 2.20 && Accuracy: 13%\n",
      "[Step 600] : Loss 2.20 && Accuracy: 10%\n",
      "[Step 700] : Loss 2.20 && Accuracy: 11%\n",
      "[Step 800] : Loss 2.20 && Accuracy: 8%\n",
      "[Step 900] : Loss 2.20 && Accuracy: 6%\n",
      "[Step 1000] : Loss 2.20 && Accuracy: 7%\n",
      "[Step 1100] : Loss 2.20 && Accuracy: 12%\n"
     ]
    }
   ],
   "source": [
    "loss = 0\n",
    "num_correct = 0\n",
    "print(\"ForwardPass\")\n",
    "for i, (im, label) in enumerate(zip(X_train, y_train)):\n",
    "    _, l, acc = forward(im, label)\n",
    "    loss += l\n",
    "    num_correct += acc\n",
    "\n",
    "    # Print starts every 100 steps.\n",
    "    if i % 100 == 99:\n",
    "        print(\n",
    "            \"[Step %d] : Loss %.2f && Accuracy: %d%%\" % (i + 1, loss / 100, num_correct)\n",
    "        )\n",
    "        loss = 0\n",
    "        num_correct = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BackPropagation\n",
      "[Step 100] : Loss 2.066 && Accuracy: 21%\n",
      "[Step 200] : Loss 1.941 && Accuracy: 35%\n",
      "[Step 300] : Loss 1.901 && Accuracy: 32%\n",
      "[Step 400] : Loss 1.726 && Accuracy: 46%\n",
      "[Step 500] : Loss 1.551 && Accuracy: 52%\n",
      "[Step 600] : Loss 1.502 && Accuracy: 60%\n",
      "[Step 700] : Loss 1.146 && Accuracy: 67%\n",
      "[Step 800] : Loss 1.188 && Accuracy: 59%\n",
      "[Step 900] : Loss 1.097 && Accuracy: 64%\n",
      "[Step 1000] : Loss 1.012 && Accuracy: 71%\n",
      "[Step 1100] : Loss 0.898 && Accuracy: 77%\n"
     ]
    }
   ],
   "source": [
    "def train(im, label, lr=.005):\n",
    "  \n",
    "  # Forward\n",
    "  out, loss, acc = forward(im, label)\n",
    "\n",
    "  # Calculate initial gradient\n",
    "  gradient = np.zeros(10)\n",
    "  gradient[label] = -1 / out[label]\n",
    "\n",
    "  # Backprop\n",
    "  gradient = soft.backprop(gradient, lr)\n",
    "  gradient = pool.backprop(gradient)\n",
    "  gradient = conn.backprop(gradient, lr)\n",
    "\n",
    "  return loss, acc\n",
    "\n",
    "print(\"BackPropagation\")\n",
    "loss = 0\n",
    "num_correct = 0\n",
    "for i, (im, label) in enumerate(zip(X_train,y_train)):\n",
    "  if i % 100 == 99:\n",
    "    print(\n",
    "      '[Step %d] : Loss %.3f && Accuracy: %d%%' %\n",
    "      (i + 1, loss / 100, num_correct)\n",
    "    )\n",
    "    loss = 0\n",
    "    num_correct = 0   \n",
    "\n",
    "  l, acc = train(im, label)\n",
    "  loss += l\n",
    "  num_correct += acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
